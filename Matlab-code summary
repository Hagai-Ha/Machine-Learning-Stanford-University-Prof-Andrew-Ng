################################   Week 2: Linear Regression   ################################
Linear regression

Hypothesis function:
h(X, theta) = X * theta

Cost function:
J(theta) = J = ((h-y)'*(h-y))/(2*m)

Gradient Descent:
theta = theta - (alpha/m) * X' * (h - y)

Normal Equation:    (more efficient than Gradient Descent if the number of features is n<10,000)
θ=pinv(X'X)X'y

################################   Week 3: Regularization, Logistic Regression   ################################

Logistic regression (sigmoid function)

Logistic Regression Hypothesis function:
h(X, theta) = 1 / ( 1 + e^(-theta' * X)  )

Decision boundary:
theta' * X = 0
y = 1 if theta' * X >= 0
y = 0 if theta' * X < 0

Logistic Regression Cost function:
J = (1/m) * sum(Cost(h,y))
if y = 1 --> Cost = -log(h)
if y = 0 --> Cost = -log(1-h)
    |
    |
    V
Cost = -y*log(h) -(1-y)log(1-h)
J = (1/m) * ( -y'*log(h) -(1-y)'*log(1-h) )

Gradient Descent:
theta = theta -(alpha/m)*X'*(h-y)

# Examples of more advanced and a lot more complexed algorithms which could be used instead of Gradient Descent:
# "Conjugate gradient"
# "BFGS"
# "L-BFGS"
# All the said algorithms choose the learning rate "alpha" automatically, and often compute theta faster. They are usually learned in courses of advanced numerical computing methods. They could be implemented easily using certain libraries (Tip: try out different libraries, since some have better implementations than others...)

# Multiclass classification: One-Vs-All


# Underfitting = high bias
# Overfitting = high variance (for example due to using a too high polynomial order while choosing the features)
# Both do not generalize well, and fail to predict "new" data.

# Addressing overfitting:
# 1. Reduce the number of features:
#       - manually or automatically choosing and keeping the most important features.
# 2. Regularization:
#       - reducing the magnitude of the values of theta. This method is favorable if there are a lot of features, and each of them contributes equally important to the prediction.

# Regularization

Regularized Linear Regression:

# delta = d(theta)/d(J) = "the gradient"

Cost function:
J(theta) = J = (1/(2*m))*( (h-y)'*(h-y) + lambda*theta'*theta )

Gradient Descent:
theta0 = theta0 -(alpha/m)*X0'*(h-y)
theta = theta -alpha*delta
theta = theta*(1-(alpha*lambda)/m) - (alpha/m) * X' * (h - y)             # for theta 1...n (we don't regularize theta0)

Normal Equation:    
θ=pinv(X'X + lambda*L)X'y
    where L = [] an (n+1 x n+1) Identity matrix, with the first element switched to 0. i.e. I[0,0] = 0
    Regularizing the Normal Equation also helps with the uninvertibility problem.

Regularized Logistic Regression:

z = X*theta; % (m x 1) = (m x n+1) * (n+1 x 1)
h = sigmoid(z); % (m x 1)

Cost function:
J = (1/m) * ( -y'*log(h) -(1-y)'*log(1-h) ) + (lambda/(2*m)) * theta(2:length(theta))'*theta(2:length(theta))

delta(j) = gradient(j) = (1/m) * x(j) * (h-y) + (lambda/m)*theta(j)         # For all j > 0
grad = (1/m) * X'*(h-y); % (n+1 x 1)
grad(2:length(grad)) = grad(2:length(grad)) + (lambda/m)*theta(2:length(grad)); % adding Reg to all theta except theta0 (theta(1))

################################   Week 4: Multi-class logistic regression classifiers & Neural Networks   ################################

# Multi-class logistic regression classifiers:
# Multi-class LR classifiers can be implemented using the "One Vs. All" method, in which each class (or label) in its turn, is being tested against all other options.

# Insted of treating "y_i" as a binary scalar, it is treated as a a k-dimensional binary vector (where "k" is the number of classes/labels).
# For example: y = [0;0;1;0] corresponds to a case in which a sample belongs to class #3, out of a total of 4 different classes.

% MATLAB built-in optimization functions:
%       fmincg works similarly to fminunc, but is more efficient when we
%       are dealing with large number of parameters.

% This is a for-loop implementation that matches a theta (n+1 dimensional vector) to each class/label. It is finally stored to creat all_theta (k x +1 dimensional matrix).
for c = 1:num_labels
    % Set Initial theta
    initial_theta = zeros(n + 1, 1);
    %     
    % Set options for fminunc
    options = optimset('GradObj', 'on', 'MaxIter', 50);
    
    % Run fmincg to obtain the optimal theta
    % This function will return theta and the cost 
    [theta] = fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), initial_theta, options); % (n+1 x 1)
    all_theta(c,:) = theta';
end

# This is a vectorized implementation that takes all_theta matrix calculated above, and creates the final prediction vector p (m x 1):

% all_theta (k x n+1)
% X (m x n+1)
all_z = X * all_theta' ; % (m x k) =  (m x n+1) * (k x n+1)'
all_h = 1./(1+exp(-all_z)) ; % (m x k)
%    M = max(X,[],DIM) or [M,I] = max(X,[],DIM) operates along the dimension DIM.
[MaxVal, MaxIndex] = max(all_h,[],2); % (m x 1) , (m x 1)
p = MaxIndex; % (m x 1)

# Implementation of Neural Network Forward Propagation with precalculated weights and 1 hidden layer:
% num_labels = 10
% Theta1 has size 25 x 401 (25 x n+1)
% Theta2 has size 10 x 26
X = [ones(m,1) X]; % adding 1's as intercept column. (m x n+1)

% from Input to hidden layer:
z2 = X * Theta1'; % (m x 25) = (m x n+1) * (25 x n+1)'
a2 = sigmoid(z2); % (m x 25)
a2 = [ones(m,1) a2]; % (m x 26)

% from Hidden to output layer:
z3 = Theta2 * a2'; % (num_labels x m) = (10 x 26) * (26 x m)
z3 = a2 * Theta2'; % (m x num_labels) = (m x 26) * (10 x 26)'
a3 = sigmoid(z3); % (m x num_labels)
h_all = a3; % (m x num_labels)

[MaxValue, MaxIndex] = max(h_all,[],2);
p = MaxIndex; % (m x 1)

################################   Week 5: Backpropagation, Neural Networks   ################################

The cost function is a generalization of the LR cost function.

Neural network Cost Function:
J = -(1/m) * SUM(i=1->m){ SUM(k=1->K){ [ y_k^(i) * log(h_k) + (1 - y_k^(i) ) * log(1-h_k)] }} + (lambda/(2*m))* SUM(l=0->L-1){ SUM(i=1->s_l){ SUM(j=1->s_l+1){ [Theta_j,i^(l)]^2 }}}

Where:
L = total number of layers in the network
s_l = number of units (not counting bias unit) in layer l
K = number of output units/classes
h_k = the hypothesis that results in the kth output.

# Backpropagation

# Important: For each training example (x_i, y_i), Forward propagation and Backpropagation are done immediately one after the other, and only then Forward propagation is computed for the next training example (x_i+1, y_i+1)

# Partial derivatives of the cost function J(Theta) = dJ/d(theta_ij^l)
dJ/d(theta_ij^l)  =  D_ij^l 
# Where D is a matrix of the deltas calculated through the process of backpropagation and corresponding to layer "l" (lower case "L")

# delta could also be defined as such:
delta_j^(l) = d[cost(t)]/d(z_j^(l)) # partial derivative of the cost function with respect to the t'th training example.

delta_j^(l) = sum[ Theta_ij^(l) * delta_i^(l+1) ]  # for i in 1:s_(l+1)  # for l in 2:(L-1)  # for j in 1:s_l

# Implementation note:
# The matrix forms for Theta(l) and for D(l) (which represent the partial derivatives of J w.r.t. theta i.e. the gradient)
# are a more comfortable for doing Forward propagation & Backpropagation (taking advantage of the effecient vectorization and matrix multiplication methods).
# On the other hand, when using advanced optimization algorithms (such as "fminunc") it is better to "unroll" those matrices into long vectors, and reshape them later back into matrices.
# This can be done in MATLAB as follows:
# Unrolling:
thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]
deltaVector = [ D1(:); D2(:); D3(:) ]
# Reshaping:
Theta1 = reshape(thetaVector(1:110),10,11)
Theta2 = reshape(thetaVector(111:220),10,11)
Theta3 = reshape(thetaVector(221:231),1,11)








