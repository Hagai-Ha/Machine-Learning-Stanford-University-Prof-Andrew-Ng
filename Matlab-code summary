################################   Week 2: Linear Regression   ################################
Linear regression

Hypothesis function:
h(X, theta) = X * theta

Cost function:
J(theta) = J = ((h-y)'*(h-y))/(2*m)

Gradient Descent:
theta = theta - (alpha/m) * X' * (h - y)

Normal Equation:    (more efficient than Gradient Descent if the number of features is n<10,000)
θ=pinv(X'X)X'y

################################   Week 3: Regularization, Logistic Regression   ################################

Logistic regression (sigmoid function)

Logistic Regression Hypothesis function:
h(X, theta) = 1 / ( 1 + e^(-theta' * X)  )

Decision boundary:
theta' * X = 0
y = 1 if theta' * X >= 0
y = 0 if theta' * X < 0

Logistic Regression Cost function:
J = (1/m) * sum(Cost(h,y))
if y = 1 --> Cost = -log(h)
if y = 0 --> Cost = -log(1-h)
    |
    |
    V
Cost = -y*log(h) -(1-y)log(1-h)
J = (1/m) * ( -y'*log(h) -(1-y)'*log(1-h) )

Gradient Descent:
theta = theta -(alpha/m)*X'*(h-y)

# Examples of more advanced and a lot more complexed algorithms which could be used instead of Gradient Descent:
# "Conjugate gradient"
# "BFGS"
# "L-BFGS"
# All the said algorithms choose the learning rate "alpha" automatically, and often compute theta faster. They are usually learned in courses of advanced numerical computing methods. They could be implemented easily using certain libraries (Tip: try out different libraries, since some have better implementations than others...)

# Multiclass classification: One-Vs-All


# Underfitting = high bias
# Overfitting = high variance (for example due to using a too high polynomial order while choosing the features)
# Both do not generalize well, and fail to predict "new" data.

# Addressing overfitting:
# 1. Reduce the number of features:
#       - manually or automatically choosing and keeping the most important features.
# 2. Regularization:
#       - reducing the magnitude of the values of theta. This method is favorable if there are a lot of features, and each of them contributes equally important to the prediction.

# Regularization

Regularized Linear Regression:

# delta = d(theta)/d(J) = "the gradient"

Cost function:
J(theta) = J = (1/(2*m))*( (h-y)'*(h-y) + lambda*theta'*theta )

Gradient Descent:
theta0 = theta0 -(alpha/m)*X0'*(h-y)
theta = theta -alpha*delta
theta = theta*(1-(alpha*lambda)/m) - (alpha/m) * X' * (h - y)             # for theta 1...n (we don't regularize theta0)

Normal Equation:    
θ=pinv(X'X + lambda*L)X'y
    where L = [] an (n+1 x n+1) Identity matrix, with the first element switched to 0. i.e. I[0,0] = 0
    Regularizing the Normal Equation also helps with the uninvertibility problem.

Regularized Logistic Regression:

z = X*theta; % (m x 1) = (m x n+1) * (n+1 x 1)
h = sigmoid(z); % (m x 1)

Cost function:
J = (1/m) * ( -y'*log(h) -(1-y)'*log(1-h) ) + (lambda/(2*m)) * theta(2:length(theta))'*theta(2:length(theta))

delta(j) = gradient(j) = (1/m) * x(j) * (h-y) + (lambda/m)*theta(j)         # For all j > 0
grad = (1/m) * X'*(h-y); % (n+1 x 1)
grad(2:length(grad)) = grad(2:length(grad)) + (lambda/m)*theta(2:length(grad)); % adding Reg to all theta except theta0 (theta(1))

################################   Week 4: Multi-class logistic regression classifiers & Neural Networks   ################################

# Multi-class logistic regression classifiers:
# Multi-class LR classifiers can be implemented using the "One Vs. All" method, in which each class (or label) in its turn, is being tested against all other options.

# Insted of treating "y_i" as a binary scalar, it is treated as a a k-dimensional binary vector (where "k" is the number of classes/labels).
# For example: y = [0;0;1;0] corresponds to a case in which a sample belongs to class #3, out of a total of 4 different classes.

% MATLAB built-in optimization functions:
%       fmincg works similarly to fminunc, but is more efficient when we
%       are dealing with large number of parameters.

% This is a for-loop implementation that matches a theta (n+1 dimensional vector) to each class/label. It is finally stored to creat all_theta (k x +1 dimensional matrix).
for c = 1:num_labels
    % Set Initial theta
    initial_theta = zeros(n + 1, 1);
    %     
    % Set options for fminunc
    options = optimset('GradObj', 'on', 'MaxIter', 50);
    
    % Run fmincg to obtain the optimal theta
    % This function will return theta and the cost 
    [theta] = fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), initial_theta, options); % (n+1 x 1)
    all_theta(c,:) = theta';
end

# This is a vectorized implementation that takes all_theta matrix calculated above, and creates the final prediction vector p (m x 1):

% all_theta (k x n+1)
% X (m x n+1)
all_z = X * all_theta' ; % (m x k) =  (m x n+1) * (k x n+1)'
all_h = 1./(1+exp(-all_z)) ; % (m x k)
%    M = max(X,[],DIM) or [M,I] = max(X,[],DIM) operates along the dimension DIM.
[MaxVal, MaxIndex] = max(all_h,[],2); % (m x 1) , (m x 1)
p = MaxIndex; % (m x 1)

# Implementation of Neural Network Forward Propagation with precalculated weights and 1 hidden layer:
% num_labels = 10
% Theta1 has size 25 x 401 (25 x n+1)
% Theta2 has size 10 x 26
X = [ones(m,1) X]; % adding 1's as intercept column. (m x n+1)

% from Input to hidden layer:
z2 = X * Theta1'; % (m x 25) = (m x n+1) * (25 x n+1)'
a2 = sigmoid(z2); % (m x 25)
a2 = [ones(m,1) a2]; % (m x 26)

% from Hidden to output layer:
z3 = Theta2 * a2'; % (num_labels x m) = (10 x 26) * (26 x m)
z3 = a2 * Theta2'; % (m x num_labels) = (m x 26) * (10 x 26)'
a3 = sigmoid(z3); % (m x num_labels)
h_all = a3; % (m x num_labels)

[MaxValue, MaxIndex] = max(h_all,[],2);
p = MaxIndex; % (m x 1)

################################   Week 5: Backpropagation, Neural Networks   ################################

The cost function is a generalization of the LR cost function.

Neural network Cost Function:
% In pure MATLAB:
J = -(1/m)*sum(sum(y_bin .* log(h) + (1-y_bin) .* log(1-h) )) + (lambda/(2*m)) * ( sum(Theta1_reg, "all") + sum(Theta2_reg, "all") );
% In the above formula:
% y_bin is a binary (m x k) dimensional matrix.
% h is a non-binary (m x k) dimensional matrix, and each value represent the probability / prediction rate for example i(1:m) to be labeled as j(1:k).

# Mathematical representation:
J = -(1/m) * SUM(i=1->m){ SUM(k=1->K){ [ y_k^(i) * log(h_k) + (1 - y_k^(i) ) * log(1-h_k)] }} + (lambda/(2*m))* SUM(l=0->L-1){ SUM(i=1->s_l){ SUM(j=1->s_l+1){ [Theta_j,i^(l)]^2 }}}
Where:
L = total number of layers in the network
s_l = number of units (not counting bias unit) in layer l
K = number of output units/classes
h_k = the hypothesis that results in the kth output.

# Backpropagation

# Important: For each training example (x_i, y_i), Forward propagation and Backpropagation are done immediately one after the other, and only then Forward propagation is computed for the next training example (x_i+1, y_i+1)
for i = 1:m,
   Perform forward propagation and backpropagation using example (x(i),y(i))
   (Get activations a(l) and delta terms d(l) for l = 2,...,L

# Partial derivatives of the cost function J(Theta) = dJ/d(theta_ij^l)
dJ/d(theta_ij^l)  =  D_ij^l 
# Where D is a matrix of the deltas calculated through the process of backpropagation and corresponding to layer "l" (lower case "L")

# delta could also be defined as such:
delta_j^(l) = d[cost(t)]/d(z_j^(l)) # partial derivative of the cost function with respect to the t'th training example.

delta_j^(l) = sum[ Theta_ij^(l) * delta_i^(l+1) ]  # for i in 1:s_(l+1)  # for l in 2:(L-1)  # for j in 1:s_l

# Implementation note:
# The matrix forms for Theta(l) and for D(l) (which represent the partial derivatives of J w.r.t. theta i.e. the gradient)
# are a more comfortable for doing Forward propagation & Backpropagation (taking advantage of the effecient vectorization and matrix multiplication methods).
# On the other hand, when using advanced optimization algorithms (such as "fminunc") it is better to "unroll" those matrices into long vectors, and reshape them later back into matrices.
# This can be done in MATLAB as follows:
# Unrolling:
thetaVector = [ Theta1(:); Theta2(:); Theta3(:); ]
deltaVector = [ D1(:); D2(:); D3(:) ] # = gradientVec
# Optimization function:
function [jval, gradientVec] = costFunction(thetaVector)
# Reshaping:
Theta1 = reshape(thetaVector(1:110),10,11)
Theta2 = reshape(thetaVector(111:220),10,11)
Theta3 = reshape(thetaVector(221:231),1,11)

# Gradient checking: 
# numerically computing the gradients (a very slow process) in order to verify that the backpropagation process is not bugged, and so GradientVec ~=~ DeltaVec
# implemented using the geometrical definition of a slope, in the context of tangent line to a function J in point(theta).
#
epsilon = 1e-4;
for i = 1:n,
  thetaPlus = theta;
  thetaPlus(i) += epsilon;
  thetaMinus = theta;
  thetaMinus(i) -= epsilon;
  gradApprox(i) = (J(thetaPlus) - J(thetaMinus))/(2*epsilon)
end;
# gradApprox ~=~ deltaVector # up to a few decimal points


# Random initialization of Theta: Breaking the symmetry.
# In logistic regression, the vector theta can be initialized to a zeros (n+1 , 1) vector.
# In neural networks on the other, such approach of giving all the "weights" the same value (be it zero or a different real number), does not work.
# Such approach would in turn creat the same values of a_i^(l) [for i in 1:s_l] ultimately turning all of the nodes into redundant copies of each other.
# To avoid this, one can randomly initialize the Theta matrix with different and unique values (say between +epsilon and -epsilon).
# MATLAB implementation:
If the dimensions of Theta1 is 10x11, Theta2 is 10x11 and Theta3 is 1x11.
#
Theta1 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
Theta2 = rand(10,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
Theta3 = rand(1,11) * (2 * INIT_EPSILON) - INIT_EPSILON;
#
# *One effective strategy for choosing INIT_EPSILON is to base it on the number of units in the network.
# A good choice of INIT_EPSILON is INIT_EPSILON = sqrt( 6/(L_in + L_out) ) where L_in = s_l and L_out = s_(l+1) are the number of units in the layers adjacent to Theta^(l).



# Neural network so far: Putting it together
# Choose architecture - usually 1 hidden layer with a number of units between 1~3 times the number of features. Possibly add a few more hidden layers with a similar number of units.
# Initialize Thetas (break symmetry)
# Compute J(Theta)
# Use a for-loop (or more advanced vectorization methods) to iterate over all training examples (x_i, y_i) where i = 1:m
#   Forward propagation + Backpropagation (for each training example x_i,y_i)
# Gradient checking (disabled once checked)
# Minimize J(Theta) using algorithm descent or another more advanced optimization algorithm


% Technical implementation note:
% This is how one can transform the labels vector y from an m-dimensional vector of values (1,2,...,k) to a BINARY (m x k) dimensional matrix.
y = [1; 1; 2; 3; 4; 4];
m = length(y);
k = num_labels = max(y); % or max(y)+1 if there is a "0" label.
y_bin = zeros(m,k);

% Method 1 - for loop:
for i = 1:m
    y_bin(i, y(i)) = 1;
end

% Method 2 - vectorized
index = (y-1).*m+(1:m)'; % [0; 0; 1; 2; 3; 3] .* 6 + [1, 2, 3, 4, 5, 6] = [0; 0; 6; 12; 18; 18] + [1, 2, 3, 4, 5, 6] % (6 x 1) + (1 x 6) = (6 x 6)
% Intuitively - in the above expression, (1:m) determines the "row", while (y-1) determines how many columns "to the right".
% index =
%     1     2     3     4     5     6
%     1     2     3     4     5     6
%     7     8     9    10    11    12
%    13    14    15    16    17    18
%    19    20    21    22    23    24
%    19    20    21    22    23    24
y_bin(index) = 1; % Linear indexing - taking only the diagonal!
y_bin

% Method 3 - using the function - sub2ind(size, rows, columns)
index = sub2ind(size(y_bin), 1:m, y'); % index = [1     2     9    16    23    24]
y_bin(index) = 1; % Linear indexing



# Example of a MATLAB function calculating the cost function J and the gradients, through the process of backpropagation:
function [J grad] = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda)
% Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices
% for our 2 layer neural network
Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), hidden_layer_size, (input_layer_size + 1));
Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), num_labels, (hidden_layer_size + 1));
% Setup some useful variables
m = size(X, 1);
% Architecture:
% Number of nodes in Input layer: n+1 = 401
% Number of hidden layers: L-2 = 1
% Number of nodes in hidden layer #1: size(Theta1,1) + 1 = hidden_layer_size + 1 = 26
% Number of nodes in Output layer: num_labels = 10
% Theta1 dimensions: (hidden_layer_size x n+1) = (25 x 401)
% Theta2 dimensions: (num_labels x hidden_layer_size+1) = (10 x 26)
% X_data should be an (m x n+1       ) dimensional matrix
% Y_data should be an (m x num_labels) dimensional matrix
n = size(X,2);
X = [ones(m,1) X]; % adding 1's as intercept/bias column. (m x n+1)
y_bin = zeros(m,num_labels); %size(y_bin) = 5000 x 10 = m x num_labels
index_y = sub2ind(size(y_bin), 1:m, y'); % (1 x m)
y_bin(index_y) = 1; % Linear indexing
% Feedforward propagation:
% from Input to hidden layer:
z2 = X * Theta1'; % (m x hidden_layer_size) = (m x n+1) * (hidden_layer_size x n+1)'
a2 = sigmoid(z2); % (m x hidden_layer_size)
a2 = [ones(m,1) a2]; % (m x hidden_layer_size+1)
% from hidden layer to Output layer:
z3 = a2 * Theta2'; % (m x num_labels) = (m x hidden_layer_size+1) * (num_labels x hidden_layer_size+1)'
% h = a3
h = sigmoid(z3); % (m x num_labels)
Theta1_reg = Theta1(:,2:end).^2;
Theta2_reg = Theta2(:,2:end).^2;
J = -(1/m)*sum(sum(y_bin .* log(h) + (1-y_bin) .* log(1-h) )) + (lambda/(2*m)) * ( sum(Theta1_reg, "all") + sum(Theta2_reg, "all") );
D1 = 0;
D2 = 0;
for i = 1:m
    % Feed forward propagation:
    a1 = X(i,:); % (1 x n+1)
    z2 = Theta1 * a1'; % (hidden_layer_size x n+1) * (1 x n+1)' = (hidden_layer_size x 1)
    a2 = sigmoid(z2); % (hidden_layer_size x 1)
    a2 = [1 ; a2]; % (hidden_layer_size + 1 x 1)
    z3 = Theta2 * a2; % (num_labels x hidden_layer_size + 1) * (hidden_layer_size + 1 x 1) = (num_labels x 1)
    h_i = sigmoid(z3); % (num_labels x 1)

    % Backpropagation
    delta_L = h_i - y_bin(i,:)'; % (num_labels x 1)
    delta_l2 = Theta2' * delta_L .* sigmoidGradient([1; z2]); % (num_labels x hidden_layer_size + 1)' * (num_labels x 1) = (hidden_layer_size + 1 x 1)
    delta_l2 = delta_l2(2:end); % discarding the delta of the bias unit. (hidden_layer_size x 1)
    D2 = D2 + delta_L * a2'; % (1x1) + (num_labels x 1) * (hidden_layer_size + 1 x 1)' = (num_labels x hidden_layer_size + 1)
    D1 = D1 + delta_l2 * a1; % (hidden_layer_size x 1) * (1 x n+1) = (hidden_layer_size x n+1)
end
Theta1_grad = D1./m; % (hidden_layer_size x n+1)
Theta2_grad = D2./m; % (num_labels x hidden_layer_size + 1)
reg1 = (lambda/m)* Theta1(:,2:end); % (hidden_layer_size x n+1-1)
Theta1_grad(:,2:end) = Theta1_grad(:,2:end) + reg1;
reg2 = (lambda/m)* Theta2(:,2:end); % (num_labels x hidden_layer_size+1-1)
Theta2_grad(:,2:end) = Theta2_grad(:,2:end) + reg2;
% Unroll gradients
grad = [Theta1_grad(:) ; Theta2_grad(:)];
end


################################   Week 6: Applied Machine Learning & System Design    ################################

Strategies for debugging a learning algorithm:
- More training examples
- Smaller set of features (use less of them to avoid overfitting)
- Getting additional features (to describe the data better)
- Adding polynomial features (allowing for more complex decision boundaries etc.)
- Decreasing/Increasing the learning rate alpha or the regularization parameter lambda.




















